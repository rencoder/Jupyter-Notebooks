{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Named Entities using NLTK and spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our two favorite imports ðŸ˜› "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy, nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And good old pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = open(\"testfile.txt\", \"rb\",).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run spaCy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = nlp(unicode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View named entities\n",
    "See: https://spacy.io/docs/usage/entity-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Entity Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January 2017</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netezza</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Entity Entity Type\n",
       "0  January 2017        DATE\n",
       "1         Quinn      PERSON\n",
       "2          Ruby     PRODUCT\n",
       "3        Python     PRODUCT\n",
       "4       Netezza      PERSON"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(x.text, x.label_, ) for x in doc.ents], columns = [\"Entity\", \"Entity Type\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Part of Speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As</td>\n",
       "      <td></td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>DATE</td>\n",
       "      <td>CD</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token Entity Type  Tag Part of Speech\n",
       "0       As               IN            ADP\n",
       "1       of               IN            ADP\n",
       "2  January        DATE  NNP          PROPN\n",
       "3     2017        DATE   CD            NUM\n",
       "4        ,                ,          PUNCT"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos = pd.DataFrame([(x.text, x.ent_type_, x.tag_, x.pos_) for x in doc], columns = [\"Token\", \"Entity Type\", \"Tag\", \"Part of Speech\"])\n",
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying domain-specific terms\n",
    "One way we could extract programming language names and such domain-specific terms is by looking for proper nouns. However, this would merely identify single-word terms; we would miss out terms such as _Ruby on Rails_. Also, we would still have to have a master list to compare and identify our terms of interest from the proper nouns list. The noun chunks list does not contain the term _Ruby on Rails_ either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Part of Speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mr.</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C++</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C#</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rails</td>\n",
       "      <td></td>\n",
       "      <td>NNPS</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Python</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Netezza</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BrassRing</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Excel</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>March</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>January</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>University</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Marvel</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Studios</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Department</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Physical</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Sciences</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>University</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Awesomeness</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Complexly</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Physical</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Phenomenon</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Masters</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Mr.</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Mr.</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Linux</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Hardy</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Heron</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Linux</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Linux</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Mint</td>\n",
       "      <td></td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Ubuntu</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Paul</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Graham</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Y</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Combinator</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Paul</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Graham</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token Entity Type   Tag Part of Speech\n",
       "2        January        DATE   NNP          PROPN\n",
       "7            Mr.               NNP          PROPN\n",
       "8          Quinn      PERSON   NNP          PROPN\n",
       "13             C               NNP          PROPN\n",
       "15           C++               NNP          PROPN\n",
       "17            C#               NNP          PROPN\n",
       "19          Ruby     PRODUCT   NNP          PROPN\n",
       "21         Rails              NNPS          PROPN\n",
       "24        Python     PRODUCT   NNP          PROPN\n",
       "31       Netezza      PERSON   NNP          PROPN\n",
       "33     BrassRing      PERSON   NNP          PROPN\n",
       "38     Microsoft         ORG   NNP          PROPN\n",
       "39         Excel     PRODUCT   NNP          PROPN\n",
       "41         March        DATE   NNP          PROPN\n",
       "44       January        DATE   NNP          PROPN\n",
       "55    University         ORG   NNP          PROPN\n",
       "57     Cambridge         ORG   NNP          PROPN\n",
       "66        Marvel         ORG   NNP          PROPN\n",
       "67       Studios         ORG  NNPS          PROPN\n",
       "76    Department         ORG   NNP          PROPN\n",
       "78      Physical         ORG   NNP          PROPN\n",
       "79      Sciences         ORG  NNPS          PROPN\n",
       "81   Engineering         ORG   NNP          PROPN\n",
       "83    University         ORG   NNP          PROPN\n",
       "85   Awesomeness         ORG   NNP          PROPN\n",
       "98     Complexly         ORG   NNP          PROPN\n",
       "100     Physical         ORG   NNP          PROPN\n",
       "101   Phenomenon         ORG   NNP          PROPN\n",
       "119      Masters      PERSON   NNP          PROPN\n",
       "122          Mr.               NNP          PROPN\n",
       "123        Quinn      PERSON   NNP          PROPN\n",
       "128          Mr.               NNP          PROPN\n",
       "129        Quinn      PERSON   NNP          PROPN\n",
       "140        Linux     PRODUCT   NNP          PROPN\n",
       "143        Hardy      PERSON   NNP          PROPN\n",
       "144        Heron      PERSON   NNP          PROPN\n",
       "154        Linux     PRODUCT   NNP          PROPN\n",
       "159        Linux     PRODUCT   NNP          PROPN\n",
       "160         Mint               NNP          PROPN\n",
       "164       Ubuntu         ORG   NNP          PROPN\n",
       "178         Paul      PERSON   NNP          PROPN\n",
       "179       Graham      PERSON   NNP          PROPN\n",
       "194            Y         ORG   NNP          PROPN\n",
       "196   Combinator         ORG   NNP          PROPN\n",
       "198         Paul      PERSON   NNP          PROPN\n",
       "199       Graham      PERSON   NNP          PROPN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos[df_pos[\"Part of Speech\"] == \"PROPN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[January,\n",
       " the mysterious Mr. Quinn,\n",
       " working knowledge,\n",
       " C,\n",
       " Rails,\n",
       " He,\n",
       " Netezza,\n",
       " March,\n",
       " He,\n",
       " his Masters,\n",
       " Mathematics,\n",
       " the University,\n",
       " Cambridge,\n",
       " He,\n",
       " an intern,\n",
       " Marvel Studios,\n",
       " his Bachelors study,\n",
       " The Department,\n",
       " Physical Sciences,\n",
       " University,\n",
       " Awesomeness,\n",
       " their supercomputing cluster,\n",
       " simulations,\n",
       " Complexly,\n",
       " Physical Phenomenon,\n",
       " He,\n",
       " modern twistor theory,\n",
       " breakfast,\n",
       " string theory,\n",
       " lunch,\n",
       " his Masters thesis,\n",
       " Mr. Quinn,\n",
       " himself,\n",
       " new flavors,\n",
       " Linux,\n",
       " Hardy Heron,\n",
       " he,\n",
       " all the releases,\n",
       " Linux,\n",
       " He,\n",
       " Linux Mint,\n",
       " Ubuntu,\n",
       " He,\n",
       " the book Hackers,\n",
       " Painters,\n",
       " Paul Graham,\n",
       " He,\n",
       " a parallel universe,\n",
       " he,\n",
       " Y-Combinator,\n",
       " Paul Graham]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.noun_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
